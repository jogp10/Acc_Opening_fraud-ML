{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) on the Bank Account Fraud (BAF) dataset\n",
    "\n",
    "This Jupyter notebook performs Exploratory Data Analysis (EDA) on one of the six synthetic tabular datasets in the Bank Account Fraud (BAF) suite of datasets. The BAF datasets were published at NeurIPS 2022 and are intended to provide a realistic, complete, and robust test bed to evaluate novel and existing methods in machine learning (ML) and fair ML."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BAF suite of datasets comprises a total of 6 different synthetic bank account fraud tabular datasets. The datasets are realistic, based on a present-day real-world dataset for fraud detection, and each dataset has distinct controlled types of bias. Additionally, the datasets have an imbalanced setting with an extremely low prevalence of positive class, contain temporal data and observed distribution shifts, and have privacy-preserving features to protect the identity of potential applicants.\n",
    "\n",
    "In this notebook, we will be exploring one of the datasets in the BAF suite, the Base.csv dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding and Exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and describing the dataset\n",
    "We start by loading the dataset into a Pandas DataFrame and displaying its first few rows using the head() function. We then display some basic statistics of the dataset using the describe() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in the data\n",
    "df = pd.read_csv('../dataset/Base.csv', header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot\n",
    "We then use the Seaborn library to create boxplots of the numerical columns in the dataset. Boxplots are used to visualize the distribution and outliers of each numerical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# get the list of numerical columns\n",
    "num_cols = df.select_dtypes(include=['float', 'int']).columns.tolist()\n",
    "\n",
    "# create a grid of subplots using seaborn\n",
    "n_cols = 3  # number of columns in the grid\n",
    "n_rows = (len(num_cols) + n_cols - 1) // n_cols  # number of rows in the grid\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(25, 5*n_rows))\n",
    "\n",
    "# loop through the columns and create a boxplot for each one\n",
    "for i, col in enumerate(num_cols):\n",
    "    row_idx = i // n_cols  # row index for this subplot\n",
    "    col_idx = i % n_cols  # column index for this subplot\n",
    "    ax = sns.boxplot(data=df[col], ax=axes[row_idx, col_idx])\n",
    "    ax.set_title(col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Outliers\n",
    "Outliers can take many different forms in a dataset. In some cases, outliers may be extreme values that fall far outside the expected range of the data, while in other cases, outliers may appear as discontinuities or gaps in the data. In this particular dataset, it has been observed that there are some columns - customer_age, days_since_request, intended_balcon_amount, and proposed_credit_limit - that contain discontinuous points. These points may represent missing data or errors in data collection, or they may be indicative of some other pattern in the data. In the next section, we will explore these columns in more detail and investigate the potential causes and implications of these discontinuous points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "label_column = 'fraud_bool'\n",
    "columns_to_analyze = ['customer_age', 'days_since_request', 'intended_balcon_amount', 'proposed_credit_limit', 'device_distinct_emails_8w']\n",
    "\n",
    "# create a grid of subplots using seaborn\n",
    "n_cols = 2  # number of columns in the grid\n",
    "n_rows = (len(columns_to_analyze) + n_cols - 1) // n_cols  # number of rows in the grid\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(25, 5*n_rows))\n",
    "\n",
    "# loop through the columns and create a boxplot for each one\n",
    "for i, col in enumerate(columns_to_analyze):\n",
    "    row_idx = i // n_cols  # row index for this subplot\n",
    "    col_idx = i % n_cols  # column index for this subplot\n",
    "    ax = sns.scatterplot(x=col, y=label_column, data=df, ax=axes[row_idx, col_idx])\n",
    "    ax.set_title(col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our analysis, it appears that there are no significant differences in the values of the variables investigated between the fraud and non-fraud categories. This suggests that outliers in these variables are not particularly informative or indicative of fraud, and may simply be due to random variations or noise in the data.\n",
    "\n",
    "Given this result, it may not be necessary to remove outliers from these variables in order to improve the accuracy of your analysis or model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing and Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot\n",
    "We then use the Seaborn library to create boxplots of the numerical columns in the dataset. Boxplots are used to visualize the distribution and outliers of each numerical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of numerical columns\n",
    "num_cols = df.select_dtypes(include=['float', 'int']).columns.tolist()\n",
    "\n",
    "# create a grid of subplots using seaborn\n",
    "n_cols = 3  # number of columns in the grid\n",
    "n_rows = (len(num_cols) + n_cols - 1) // n_cols  # number of rows in the grid\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(25, 5*n_rows))\n",
    "\n",
    "# loop through the columns and create a boxplot for each one\n",
    "for i, col in enumerate(num_cols):\n",
    "    row_idx = i // n_cols  # row index for this subplot\n",
    "    col_idx = i % n_cols  # column index for this subplot\n",
    "    ax = sns.boxplot(data=df[col], ax=axes[row_idx, col_idx])\n",
    "    ax.set_title(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the upper and lower bounds for outliers\n",
    "#num_cols = df.select_dtypes(include=['float']).columns.tolist()\n",
    "\n",
    "\n",
    "# loop through the columns and remove the outliers\n",
    "#for i, col in enumerate(num_cols):\n",
    "#    Q1 = df[col].quantile(0.25)\n",
    "#    Q3 = df[col].quantile(0.75)\n",
    "#    IQR = Q3 - Q1\n",
    "#    lower_bound = Q1 - (1.5 * IQR)\n",
    "#    upper_bound = Q3 + (1.5 * IQR)\n",
    "#    df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "#import os\n",
    "\n",
    "# get the list of numerical columns\n",
    "#num_cols = df.select_dtypes(include=['float', 'int']).columns.tolist()\n",
    "\n",
    "# create a grid of subplots using seaborn\n",
    "#n_cols = 3  # number of columns in the grid\n",
    "#n_rows = (len(num_cols) + n_cols - 1) // n_cols  # number of rows in the grid\n",
    "#fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(25, 5*n_rows))\n",
    "\n",
    "# loop through the columns and create a boxplot for each one\n",
    "#for i, col in enumerate(num_cols):\n",
    "#    row_idx = i // n_cols  # row index for this subplot\n",
    "#    col_idx = i % n_cols  # column index for this subplot\n",
    "#    ax = sns.boxplot(data=df[col], ax=axes[row_idx, col_idx])\n",
    "#    ax.set_title(col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix\n",
    "We can calculate the correlation matrix between the numerical features in the dataset to see how they are related to each other. This can give us some insight into which features are most important for predicting fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "corr_matrix = df.select_dtypes(include=['float', 'int']).corr()\n",
    "\n",
    "# Create a heatmap of the correlation matrix\n",
    "fig, ax = plt.subplots(figsize=(25, 30))\n",
    "ax = sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', annot_kws={'size': 10})\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-square test\n",
    "We want to perceive the relation between the categorical features in the dataset to see how they are related to the target variable. This can give us some insight into which features are most important for predicting fraud.\n",
    "\n",
    "(Note: chosen significance level (alpha) = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from tabulate import tabulate\n",
    "\n",
    "categorical_variables = ['payment_type', 'employment_status', 'housing_status', 'source', 'device_os']\n",
    "\n",
    "col_names = [\"Variable\", \"Chi-square Statistic\", \"Degrees of freedom\", \"P-value\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "for col in categorical_variables: \n",
    "    contingency_table = pd.crosstab(df['fraud_bool'], df[col])\n",
    "\n",
    "    chi2_stat, p_val, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "    data.append([col, chi2_stat, dof, p_val])\n",
    "\n",
    "print(tabulate(data, headers=col_names, tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this table, we have 5 columns: \n",
    "- **Variable** <br>\n",
    "Name of the variable being analised.\n",
    "\n",
    "- **Chi-square Statistic** <br> \n",
    "Measures the overall discrepancy between the observed frequencies and the expected frequencies under the assumption of independence. A larger chi-square statistic suggests a greater difference between the observed and expected frequencies.\n",
    "\n",
    "- **Degree of freedom** <br>\n",
    "Represent the number of categories in the variables minus 1. In the context of a chi-square test, it determines the critical values or the distribution of the chi-square statistic. The degrees of freedom help in assessing the statistical significance of the chi-square test.\n",
    "\n",
    "- **P-value** <br>\n",
    "Indicates the statistical significance of the association, if the p-value is below a chosen significance level (alpha < 0.05), it suggests a significant association."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through analysis of the results, we can conclude that, for all the variables analysed, in none of them the p-value is higher or equal to the chosen significance level (alpha = 0.05), only lower. What we can perceive from the fact that the p-value is zero is that the observed results are highly unlikely to be due to random chance, and there is a significant relationship or effect present in the data. As a result, we can only take conclusions based on the chi-square Statistic and the degrees of freedom of each variable. Normally, the higher the degree of freedom the higher the chi-square statistic tends to be. By observing the table, we can understand that some variables have stronger relation with the target variable, such as \"device_os\" and \"housing_status\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms\n",
    "We can also create histograms of the numerical columns to see the distribution of each feature. This can help us identify any features that may need to be transformed to achieve a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histograms of the numerical columns\n",
    "df.hist(bins=20, figsize=(25, 20))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Plot\n",
    "Finally, we can create a count plot to visualize the distribution of the target variable (fraud). This can help us identify the class imbalance in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a count plot of the target variable\n",
    "sns.countplot(x='fraud_bool', data=df)\n",
    "plt.title('Target Variable Distribution')\n",
    "plt.show()\n",
    "\n",
    "df['fraud_bool'].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous plot shows that the dataset is highly imbalanced, with only 0.01% of the data belonging to the fraud class. \n",
    "This can pose challenges in building models that accurately predict fraud, as the model may be biased towards predicting non-fraud cases.\n",
    "To address this issue, we have various techniques to deal with imbalanced datasets, such as oversampling, undersampling.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting relevant features\n",
    "In this step we select the features that have the most impact on our target variable (\"fraud_bool\"). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Encoding\n",
    "In order to encode some of our variables, we looked up some of the most used encoding methods. We ended up choosing Ordinal Encoding for High-Cardinality Variables because we have categorical variables with a high number of unique values (high-cardinality). Being that using One-Hot Encoding might lead to a large number of resulting columns and given that we want to reduce the number of columns, One-Hot Encoding turns out not being the best choice. So we decided to use Ordinal Encoding, which assigns unique integers to each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "dataset = df.copy()\n",
    "\n",
    "columns_to_encode = ['payment_type', 'employment_status', 'housing_status', 'source', 'device_os']\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "dataset[columns_to_encode] = encoder.fit_transform(dataset[columns_to_encode])\n",
    "\n",
    "#print(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Dataset\n",
    "Dealing with imbalanced datasets is an important aspect of machine learning. In this section, we will explore some techniques for dealing with imbalanced datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\t\n",
    "\n",
    "def plot_confusion_matrix(report, cm, title):\n",
    "  \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.text(1, 3.2, str(report), fontsize=12, ha='center')\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Reds')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "training_data = dataset.sample(frac=0.1, random_state=1)\n",
    "\n",
    "# Separate the features and the target variable\n",
    "X = training_data.drop('fraud_bool', axis=1)\n",
    "y = training_data['fraud_bool']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1, stratify=y)\n",
    "\n",
    "# Shuffle the training data\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=1)\n",
    "\n",
    "# Train a Random Forest classifier on the original data\n",
    "clf_original = RandomForestClassifier(random_state=1)\n",
    "clf_original.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate the original model on the test set\n",
    "y_pred_original = clf_original.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_original)\n",
    "\n",
    "report = classification_report(y_test, y_pred_original, zero_division=0)\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(report, cm, 'Confusion Matrix - Original Data')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset without any techniques applied to deal with the imbalanced dataset results in a model that is biased towards predicting non-fraud cases. As we can see from the confusion matrix, the model is not able to predict any fraud cases correctly. The f1-score is 0.00, indicating poor overall performance in identifying fraudulent cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply Random Under-sampling to balance the data\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled_rus, y_resampled_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# Train a Random Forest classifier on the balanced data using Random Under-sampling\n",
    "clf_rus = RandomForestClassifier(random_state=42)\n",
    "clf_rus.fit(X_resampled_rus, y_resampled_rus)\n",
    "\n",
    "# Evaluate the Random Under-sampling model on the test set\n",
    "y_pred_rus = clf_rus.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_rus)\n",
    "\n",
    "report = classification_report(y_test, y_pred_rus, zero_division=0)\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(report, cm, 'Confusion Matrix - Random Under-sampling')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplying a undersampling technique, we can see that the model is now able to predict some fraud cases correctly. The recall for the minority class improves significantly (0.75) indicating that the model captures a higher proportion of fraudulent cases and the f1-score improves to 0.08 indicating better overall performance in identifying fraudulent cases, but still not good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Random Over-sampling to balance the data\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled_ros, y_resampled_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a Random Forest classifier on the balanced data using Random Over-sampling\n",
    "clf_ros = RandomForestClassifier(random_state=42)\n",
    "clf_ros.fit(X_resampled_ros, y_resampled_ros)\n",
    "\n",
    "# Evaluate the Random Over-sampling model on the test set\n",
    "y_pred_ros = clf_ros.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_ros)\n",
    "\n",
    "report = classification_report(y_test, y_pred_ros, zero_division=0)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(report, cm, 'Confusion Matrix - Random Over-sampling')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplying a oversampling technique, we can see that the model doesn't improve much. The recall for the minority class is 0.01 and the f1-score is 0.03, which doesn't improve a lot from the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance the data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled_smote, y_resampled_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a Random Forest classifier on the balanced data using SMOTEENN\n",
    "clf_smote = RandomForestClassifier(random_state=42)\n",
    "clf_smote.fit(X_resampled_smote, y_resampled_smote)\n",
    "\n",
    "# Evaluate the SMOTE model on the test set\n",
    "y_pred_smote = clf_smote.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_smote)\n",
    "\n",
    "report = classification_report(y_test, y_pred_smote, zero_division=0)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(report, cm, 'Confusion Matrix - SMOTE')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Concerning the Smote technique, although the improvements were relatively small we noticed a slight improvement regarding the original dataset.\n",
    "The precision, recall, and F1-score for the minority class are still quite low compared to the majority class.\n",
    "\n",
    "## Main Takeaways\n",
    "Overall, the results confirm that the original dataset suffers from severe class imbalance, leading to poor performance in identifying fraudulent cases. While the applied techniques (under-sampling, over-sampling, and SMOTE) show some improvements in identifying fraudulent cases compared to the original dataset, the performance remains limited. Further analysis and experimentation may be required to develop a more effective model for fraud detection in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Compute the false positive rate (FPR), true positive rate (TPR), and threshold\n",
    "fpr_undersampling, tpr_undersampling, thresholds = roc_curve(y_test, y_pred_rus)\n",
    "fpr_smote, tpr_smote, thresholds = roc_curve(y_test, y_pred_smote)\n",
    "fpr_oversampling, tpr_oversampling, thresholds = roc_curve(y_test, y_pred_ros)\n",
    "\n",
    "auc_undersampling = auc(fpr_undersampling, tpr_undersampling)\n",
    "auc_smote = auc(fpr_smote, tpr_smote)\n",
    "auc_oversampling = auc(fpr_oversampling, tpr_oversampling)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(5,5), dpi=100)\n",
    "\n",
    "plt.plot(fpr_undersampling, tpr_undersampling, color='red', lw=2, label='ROC curve - Undersampling (area = %0.2f)' % auc_undersampling)\n",
    "plt.plot(fpr_smote, tpr_smote, color='green', lw=2, label='ROC curve - SMOTE (area = %0.2f)' % auc_smote)\n",
    "plt.plot(fpr_oversampling, tpr_oversampling, color='blue', lw=2, label='ROC curve - Oversampling (area = %0.2f)' % auc_oversampling)\n",
    "plt\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing modeling techniques\n",
    "The modeling techniques chosen are: \n",
    "- Naive Bayes\n",
    "- Decision Tree\n",
    "- k-Nearest Neighbours (KNN)\n",
    "- Logistic Regression\n",
    "- Support Vectors (SVM)\n",
    "- Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('fraud_bool', axis=1) #Features \n",
    "y = dataset['fraud_bool'] # Labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying models and evaluating performance\n",
    "In this section, we apply the models chosen and evaluate their performance with appropriate metrics.\n",
    "\n",
    "The metrics chosen are the following:\n",
    "- Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "Naive Bayes is a classification algorithm based on Bayes' theorem. It assumes that features are independent and calculates the probability of an instance belonging to a class. It's computationally efficient, works well with high-dimensional data, and performs best when the independence assumption holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "# Instantiate and train the Naive Bayes classifier\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('F1 Score:', f1)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree\n",
    "Decision Trees are classification algorithms that create a tree-like model of decisions. Each internal node represents a feature, and each leaf node represents a class label. They split the data based on feature values to create homogeneous subsets. When making predictions, a new instance traverses the tree to a leaf node, and the corresponding class label is assigned. Decision Trees are interpretable and handle categorical and numerical data, capturing complex decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-Nearest Neighbours (KNN) \n",
    "k-Nearest Neighbors (KNN) is a classification algorithm that predicts the class of an instance based on its k nearest neighbors in the feature space. It assumes that instances with similar features tend to belong to the same class. During training, KNN stores the feature vectors and their corresponding class labels. When making predictions, it finds the k nearest neighbors to the target instance and assigns the majority class among those neighbors as the predicted class. KNN is a simple and versatile algorithm that can handle both linear and non-linear classification tasks, making it useful in various applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "Logistic Regression is a classification algorithm that predicts the probability of an instance belonging to a specific class. It uses a sigmoid function to map input features to a binary output. By fitting a decision boundary during training, Logistic Regression separates the classes. When making predictions, it calculates the probability of an instance belonging to the positive class and applies a threshold for classification. Logistic Regression is a simple and effective algorithm suitable for binary classification tasks, handling linearly and non-linearly separable data with appropriate transformations or kernel functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vectors (SVM)\n",
    "Support Vector Machines (SVM) are powerful classifiers that can handle both linear and non-linear classification tasks. They work by finding an optimal hyperplane that maximally separates the data points of different classes. SVMs also offer various kernels (e.g., linear, polynomial, radial basis function) to capture complex relationships between the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest \n",
    "Random Forest is an ensemble learning method that combines multiple decision trees to make predictions. Each decision tree is trained on a random subset of the data, and the final prediction is determined by aggregating the predictions of individual trees. Random Forests are effective in handling complex datasets, capturing non-linear relationships, and mitigating overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Evaluation and Validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models performance on testing data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying cross-validation techniques"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation and Insights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
